# Introduction

Machine learning pipelines are widely used in antivirus (AV) systems to efficiently detect malware due to their speed and scalability. However, malware developers continually modify their malware features to evade detection. This constant evolution leads to changes in data distribution, which directly impacts model detection rates, a phenomenon known as concept drift. Traditional batch learning methods have proven inadequate in addressing malware concept drift. Recent research emphasizes drift detection strategies and modeling malware detection as ML data stream pipeline with drift detection capabilities to ensure robustness in real-world applications.


# Pervasiveness of Concept Drift
While machine learning-based malware detectors perform well in experimental settings, their real-world deployment often suffers from performance degradation over time. This is due to malware authors continually adapting and modifying malware features to evade detection - a phenomenon known as concept drift. Ceschin et al. demonstrate that concept drift is a widespread issue, not limited to specific datasets, by analyzing two well-known datasets of Android applications: DREBIN and AndroZoo. They identify two main factors driving the constant changes in malware samples. The first is periodic trends, where statistical correlations shift over time. The second is the evolution of the operating system, where the features themselves change.
To ensure that malware remains functional on newer systems while maintaining its malicious intent, malware authors must adapt to platform evolution. This involves supporting newly introduced APIs or dropping deprecated ones in response to operating system updates. For example, an analysis of the DREBIN dataset shows that malware samples using the SMS-sending feature appear and disappear in sync with changes in Android's SMS subsystem. These samples often carry out SMS jacking attacks, which secretly subscribe victims to attacker services for financial gain. This behavior reflects the ongoing arms race between Google and attackers over the SMS sending permission. Other similar patterns of malware evolution are also observed in both the DREBIN and AndroZoo dataset, confirming that concept drift is a pervasive issue.


# Concept Drift Detection Strategies

To build an effective machine learning model for malware detection in real-world settings, it is crucial to detect concept drift early, before the model's performance begins to degrade. This allows for timely retraining, ensuring the model remains capable of identifying drifted samples. A common approach to measure concept drift involves assessing the model's credibility in detecting new samples. This is often done by evaluating the probability of a test sample fitting into a particular class.
However, since class probabilities must sum to 100%, this method can be unreliable for unseen test samples that don't belong to any predefined class. For instance, suppose an ML model designed to classify samples as either HTTP or DNS finds 60% similarity between an unknown sample and an HTTP request. The model would assign 60% confidence to the HTTP classification. Given that there are only two possible classes, it would automatically predict the sample as DNS with 40% confidence. But in reality, the sample might belong to an entirely different category, such as a SKYPE request.
Because the model’s confidence or class probability is not always a reliable indicator for unseen data, alternative metrics are needed to measure the model’s credibility. 

		


propose Transcend, a framework to identify aging classification models in vivo during deployment, much before the machine learning model’s performance starts to degrade. 

Our approach uses a statistical comparison of samples seen during deployment with those used to train the model, thereby building metrics for prediction quality. 
		 	 	 		
Traditional metrics such as precision and recall are used to retrospectively indicate the model performance. However, these metrics do not assess the decision of the classifier. For exam- ple, hyperplane-based learning models (e.g., SVM) only check the side of the hyperplane where the object lies while ignoring its distance from the hyperplane 
				
This is a crucial piece of evidence to assess non-stationary test objects that eventually lead to concept drift. 
				
				

				
look at objects statistically rather than prob- abilistically. 
				
conformal evaluator. 
				
Probability:  indicative of how likely a test object is to belong to a class. 
				
Statistics: how likely is the test object to belong to a class compared to all of its other members? 
P-values vs. Probabilities 
Transcending Transcend	
			
		
			
			
		
				
			
		


[Discuss Transcend and Transcending Transcend]

# Modeling Malware Detection as ML Data Stream Pipeline with Drift Detection

Batch learning methods require processing all training samples simultaneously. When concept drift is detected, reapplying batch learning becomes time-consuming and resource-intensive. In contrast, data stream-based machine learning algorithms only need to process the new samples responsible for the drift, making them far more efficient in terms of time and resource usage.

Traditional data stream-based machine learning models that account for concept drift typically update only the classifier when drift is detected. However, Ceschin et al. extend this approach and propose Fast & Furious that also considers changes in feature extractors, demonstrating that their method significantly outperforms the traditional data stream-based approaches. Fast & Furious involves three drift detection levels - Normal, Warning, and Drift. At the normal level, only the classifier is incrementally updated with the new sample. During the warning level, the classifier is incrementally updated, and the new sample is stored in a buffer. At the drift level, both the classifier and feature extractor are retrained using the data collected in the warning level. The performance improvement achieved by incorporating the feature extractor update into the pipeline suggests that detecting changes in feature attributes, such as new API calls, permissions, and URLs, helps boost detection rates in the presence of concept drift. The Fast & Furious pipeline is illustrated in figure 1.

A key limitation of Fast & Furious is its dependence on ground truth labels, which require either manual labeling or resource intensive and costly dynamic analysis of the drifted samples with certain delay. This delay in obtaining these true labels can create a window of opportunity for attackers to exploit the model’s outdated detection capabilities, leading to a decline in the model’s overall detection performance. To address this challenge, Xu et al. introduce DroidEvolver that 
automatically and continuously updates itself during malware detection without human intervention. 

DroidEvolver operates in two phases: Initialization and Detection. During the initialization phase, it builds a feature set and a model pool containing various detection models, using samples with true labels. This is the only stage where true labels are needed. In the detection phase, predictions for unknown samples are made through weighted voting among “young” models. A model is considered young based on the Juvenilization Indicator (JI), which measures the similarity between the detected sample and previously classified samples with the same prediction label. If the JI for any model falls outside a specific range, the sample is flagged as a drifting sample, and the corresponding model is classified as an aging model.
Upon detecting a drifting sample, DroidEvolver updates all aging models using the sample and its pseudo label generated by the model pool. Simultaneously, the feature set is updated to reflect the feature changes observed in the drifting sample. This approach allows DroidEvolver to make lightweight updates with evolving feature sets and pseudo labels, avoiding the need for retraining or true labels.

While DroidEvolver excels at quickly adapting to concept drift and operates without the need for true labels, it requires maintaining a pool of models and periodically retraining the aging models, which increases resource consumption and costs. In contrast, Fast & Furious relies on ground truth for drifted samples, which can be acquired through large-scale analysis in the cloud, and it outperforms DroidEvolver in detection accuracy. So, both systems can be viewed as complementary, each addressing different challenges in the detection process.

