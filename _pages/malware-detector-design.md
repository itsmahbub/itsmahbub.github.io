---
title: "Designing an Effective Malware Detector: Key Insights"
permalink: /machine-learning-in-malware-detection/
---

How can we determine if a program is malicious or benign? Malicious software deceives users by hiding its intention until it’s too late. Once executed, the damage is already done. To detect and block a malware before it can harm user devices, we need to uncover its intention: Does the program seek to harm the user, or will it behave as expected? Unlike simple tasks, such as distinguishing an apple from an orange, malware detection is challenging because we cannot truly identify a program's intention. So, achieving 100% accuracy in malware detection is impossible. However, certain static and behavioral differences between malware and benign programs can help us identify them effectively. In this article, we will examine the design principles for machine learning-based malware detector and outline the key requirements necessary for its effectiveness.

## Malware Detector Must be Scalable, Efficient, and Robust

In the early days of cybersecurity, antivirus softwares relied on manual detection rules to identify and block malwares. However, as the number of threats and malware families grew, this approach became unsustainable. With millions of potential threats emerging daily, a more scalable and efficient solution is essential. Furthermore, the landscape of malware detection is constantly evolving, with malware writers continuously releasing new versions to evade detection. To keep pace, a malware detector must be robust and capable of adapting to these ongoing changes.

## Key Requirements for Effective Malware Detection

Machine learning-based malware detector must meet several key requirements to ensure effectiveness and adaptability. First, the models must be trained with a large, representative dataset that accurately captures the differences between malicious and benign programs in the real world. Without such a dataset, models may incorrectly classify programs; for example, they might label all large files as malicious if the training data includes large malwares but lacks large goodwares. Furthermore, these models should be interpretable to identify the root causes of false alarms, which is essential for refining both the model and the dataset. While accurate malware detection is crucial, minimizing false positives is even more important, as misclassifying legitimate programs as threats can frustrate users, potentially leading them to disable their protection and leave their devices vulnerable. Additionally, the landscape of malware detection is constantly changing, with malware authors frequently releasing new versions to evade detection. This ongoing evolution leads to concept drift, where models become outdated over time. To address this, a malware detector should be flexible, allowing for updates with new data between retraining to maintain its effectiveness.

## A Two-Stage Pre-Execution Detection Approach by Kaspersky Lab

Kaspersky Lab’s two-stage pre-execution detection approach is an efficient, robust, and interpretable method that ensures a low false-positive rate. Due to the high volume of daily malware detection requests and the time and resource requirements of machine learning models, relying solely on machine learning is impractical. To address this, Kaspersky employs a two-stage approach that combines similarity hash function with an ensemble of decision trees.

### The Pre-Detect Stage

In the first stage, known as the pre-detect stage, lightweight features are used to calculate a similarity hash function based on locality-sensitive hashing (LSH). LSH has the interesting property that almost identical files fall into the same hash bucket. As a result, a malicious executable and its slightly modified versions will fall into the same hash bucket. Similarly, almost identical benign files will be grouped into one bucket. This allows for fast classification: if a target file falls into a bucket where all files are either benign or malicious, it can be quickly categorized accordingly. However, if a file falls into a bucket with a mix of benign and malicious files, further analysis is required in the second stage - the detect stage.

### The Detect Stage

During the detect stage, specialized classifiers trained with heavy features perform a more in-depth analysis. In the second stage, bucket-specific classifiers are trained using malicious files from the same bucket along with benign files from all buckets. The pre-detect stage significantly reduces the number of files needing this costly analysis. Since the bucket-specific classifiers in the second stage handle almost identical malwares, they maintain a lower false-positive rate. This two-stage approach is interpretable because each hash bucket contains nearly identical samples and is adaptable to new threats by adding new hash buckets and classifiers without retraining the entire model.

## Addressing the Challenge of Imbalanced Datasets

In real-world scenarios, the proportion of malware to goodware is highly imbalanced, which poses a challenge for traditional machine learning approaches. These approaches often struggle with such unbalanced datasets, as they tend to bias predictions toward the majority class. Oak et al. demonstrate that the Bidirectional Encoder Representations from Transformers (BERT) pretrained large language model achieves state-of-the-art performance even with an extremely unbalanced dataset where only 0.5% of the samples are malware.

## The Limitations of Machine Learning in Malware Detection

Machine learning is effective in detecting known threats and their variations but has some limitations. Supervised learning models, for instance, require labeled data, which can be expensive and time-consuming to obtain. In contrast, unsupervised learning utilizes unlabeled data to cluster similar threats and to separate malware from benign programs more cost-effectively. This method also helps reduce the manual effort needed for labeling data in supervised learning. However, unsupervised learning has the limitation of not being able to label the threats it identifies. Deep learning, a subset of machine learning, goes a step further by inferring high-level patterns from low-level data, making it more adept at recognizing sophisticated threats. Nonetheless, deep learning models require significantly more data than traditional approaches and offer limited interpretability due to their complexity.

## How Human Experts and Machine Algorithms Approach Malware Classification

Now that we understand the key factors to consider when designing machine learning-based malware classifiers, let’s explore how human experts approach malware classification and the key differences in the decision-making processes between humans and machine algorithms.

Human experts tend to focus on dynamic features because they contain semantically rich categorical data that are easier for humans to interpret. For example, a program connecting to an unrelated web URL is suspicious to a human analyst. Although dynamic features are often less complete than static ones, humans can use complementary data to make informed decisions. However, missing information in dynamic features can reduce their usefulness in machine learning models.

On the other hand, static features are typically numeric, making it difficult for humans to perform statistical analysis and identify meaningful correlations. Machine learning models, however, excel at analyzing static features, detecting strong statistical correlations without needing deep semantic understanding.

## Complementary Skills: Humans and Machines

Both humans and machines agree on the importance of network traffic and valid signatures. However, they differ in prioritizing other features. Machine learning models prioritize PE Resources, which is the least important to human experts. Malware often embeds executables, DLLs, or large raw data within resources, a characteristic that machine learning detects through statistical analysis of large datasets. These findings suggest that humans and machines have complementary skills and much to learn from each other.
